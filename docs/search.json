[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Vanessa Salgado",
    "section": "",
    "text": "Hi! My name is Vanessa Salgado.\n\n\n\nUniversity of California, Santa Barbara | Santa Barbara, CA MEDS at Bren School of Environmental Science & Management"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Vanessa Salgado",
    "section": "",
    "text": "University of California, Santa Barbara | Santa Barbara, CA MEDS at Bren School of Environmental Science & Management"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "My Blog",
    "section": "",
    "text": "Carbon Credits Data Visualization\n\n\nAnalyzing the Distribution of Carbon Credits between Countries\n\n\n\nVanessa Salgado\n\n\nMar 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWater Stressors for Low Income Food Deficit Countries\n\n\n\nMEDS\n\n\nR\n\n\nStatistics\n\n\n\nExamining Water Use and Water Stress. Comparing Industrial, Irrigation, and Municipial Water Withdrawals\n\n\n\nVanessa Salgado\n\n\nDec 15, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n2021 Texas Blackout\n\n\nAnalyzing affected areas & socioeconomic factors that influenced recovery\n\n\n\nVanessa Salgado\n\n\nDec 15, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTest\n\n\n\nQuarto\n\n\nR\n\n\nMEDS\n\n\n\nblog post description (appears underneath the title in smaller text) which is included on the listing page\n\n\n\nVanessa\n\n\nOct 24, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "Coming Soon!\nHobbies:\n\nLearning French\nTrying out new sports\nThrifting\nLearning how to recreate My Mom‚Äôs Mexican Dishes"
  },
  {
    "objectID": "posts/2023-12-31-test-blog/index.html",
    "href": "posts/2023-12-31-test-blog/index.html",
    "title": "Test",
    "section": "",
    "text": "CitationBibTeX citation:@online{2023,\n  author = {, Vanessa},\n  title = {Test},\n  date = {2023-10-24},\n  url = {https://Vanessa-Salgado.github.io/posts/2023-12-31-test-blog/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nVanessa. 2023. ‚ÄúTest.‚Äù October 24, 2023. https://Vanessa-Salgado.github.io/posts/2023-12-31-test-blog/."
  },
  {
    "objectID": "posts/2023-12-15-water-stress/index.html",
    "href": "posts/2023-12-15-water-stress/index.html",
    "title": "Water Stressors for Low Income Food Deficit Countries",
    "section": "",
    "text": "Background and Motivation\nWater is the worlds most valuable resource and climate change will likely exacerbate water stress world wide. Water stress will further affect the most vulnerable countries. Vulnerable countries are already facing water shortages, poor water management, privatized water management, etc. Water stressors include demands from agriculture, natural disasters, industrial use , and municipal use. Water stress occurs when demand for safe, usable water in a given area exceeds the supply. I thought a good measure of vulnerability would be to study water stressors in Low income food deficit countries(LIFDCs) given that vulnerable countries often face issues of poverty and food scarcity that are often linked to water vulnerability.\nAs global population grows (increasing agricultural, industrial and domestic demands for water), and water demand increases, water stress and the risk of water scarcity is now a common concern. This is even more applicable for particular regions with lower water resources and/or larger population pressures.\nIn this study I chose to focus on the most vulnerable areas for certain reasons\na. challenge myself with missing data\nb. stray away from Eurocentric studies that focus on Western development\nc.¬†Highlight countries of need\n\n\n\nGoal\nMy overall question is: What are the biggest stressors of water resources for ‚Äúlow income food deficit countries?‚Äù Understanding what the water stressors are in each country\n\n\n\nLow Income Food Deficit Countries\n\n\n\n\nAQUASTAT Data\n\nAbout the Data\nThe AQUASTAT Dataset is the Food and Agriculure Orgnaization of the United Nations global information system on water resources and agriculture water management. It collects, analyses and provides free access to over 180 variables and indicators by country from 1960. AQUASTAT draws on national capacities and expertise with an emphasis on Africa, the Near East, countries of the former Soviet Union, Asia, and Latin America and the Caribbean. AQUASTAT plays a key role in the monitoring of the Sustainable Development Goal 6 that sets out to ‚Äúensure availability and sustainable management of water and sanitation for all‚Äù, and in particular indicators of target 6.4 on water stress and water use efficiency.\nFAO‚Äôs global Information System on Water and Agriculture can a new online platform that is The visit the AQUASTAT platform, you can visit: AQUASTAT.\n\n\n\nAnalysis Plan\n\nClean Data for Variables of Interest\nExploratory Data Analysis\nVisualize Urban population of each country by Continent 3 most important water withdrawals\n\nIrrigation\nIndustrial\nMunicipal\n\nLinear Model Relationship between Water Stress and Urban Population Relationship between Cultivated area (arable land + permanent crops)\nTime Series Data Annual freshwater withdrawals, 2019\n\nData Cleaning\nAlthought the AQUASTAT dataset was very detailed, cleaning the data resulted in a challenge. Downloading the dataset from the online platform made, resulted in a dataset with a Country, Variable, and Unit column. Below is the data cleaning process. Essentially, I had to pivot the entire table and rejoin units with their variable.\n\n\nCode\nlibrary(tidyverse)\nlibrary(tibble)\nlibrary(ggplot2)\nlibrary(purrr)\nlibrary(tidyr)\nlibrary(readr)\nlibrary(here)\nlibrary(readr)\nlibrary(janitor)\nlibrary(tsibble)\nlibrary(feasts)\nlibrary(countrycode)\nlibrary(knitr)\nlibrary(sf)\nlibrary(wbstats)\nlibrary(rnaturalearth)\n\nlibrary(raster)\nlibrary(terra)\nlibrary(spData)\nlibrary(spDataLarge)\nlibrary(tidyverse)\nlibrary(ggspatial)\nlibrary(patchwork)\n\nlibrary(tmap)\n\n\n\n\nCode\nwater_resources &lt;- read_csv(\"data/AQUASTAT_Water_Resources.csv\")\n\n# water_data &lt;- water_resources %&gt;% \n#   subset(\"Unit\", \"Symbol\") + \n#   group_by(Country, Variable) %&gt;%\n#   pivot_wider(names_from = Variable,\n#               values_from = c('\"2020\"', Symbol, Unit))\n# \n# water_data\n\nwater &lt;- read_csv(\"data/AQUASTAT_Dissemination_System.csv\")\ncolnames(water)\n\n#water &lt;-  water %&gt;% select(-\"...6\")\n\nwater5 &lt;- water \n\nsubwater &lt;- subset(water, select = -c(Variable, Unit)) \n\ncombin &lt;- paste(water$Variable, water$Unit, sep = \"_\")\n\ncombin &lt;- data.frame(combin)\n\nwater = cbind(subwater, combin)\n\ncolnames(water) &lt;- c(\"Country\", \"Symbol\", \"2020\", \"Variable\")\n\nwater1 &lt;- water %&gt;% \n  subset(select = -Symbol) %&gt;% \n  group_by(Country) %&gt;%\n  pivot_wider(names_from = (Variable),\n              values_from = \"2020\") \n\ncolnames(water1)\n\n# ---Add a new column \"Continent\" to water1 that corresponds to Country---\nwater1 &lt;- water1 %&gt;%\n  mutate(Continent = countrycode(sourcevar = Country, origin = \"country.name\", destination = \"continent\")) %&gt;% \n  dplyr::rename(Urban_population = `Urban population_1000 inhab`)\n\nwater1\n\n\n\n\nExploratory Data Analysis\nI found that the countries that are labeld LIFDCs belong to 3 continents: Asia, Africa, and the Americas with the majority in the African Continent. Below are the countries and the relative Urban Population to each country by continent.\n\nMap of Urban Population of Asia\n\nMap of Urban Population of AfricaMap of Urban Population of AsiaMap of Urban Population of Americas\n\n\n\n\nCode\nafrica = world |&gt; \n  filter(continent == \"Africa\", !is.na(iso_a2)) %&gt;% \n  dplyr::rename(Country = name_long) %&gt;%\n  right_join(urban_pop_africa, by = \"Country\") %&gt;% \n  # dplyr::select(name, subregion, gdpPercap, HDI, pop_growth, urban_pop) %&gt;% \n  st_transform(\"+proj=aea +lat_1=20 +lat_2=-23 +lat_0=0 +lon_0=25\")\n\n\nafrica_map&lt;- ggplot(africa) +\n  geom_sf() +\n  theme_bw()\n\nurban_map_africa &lt;- ggplot(africa) +\n  # geom_sf(aes(color) = HDI)) +\n  geom_sf(aes(fill = Urban_population)) +\n  theme_bw() \n\nafrica_map+urban_map_africa\n\n\n\n\n\nAfrica Urban Population\n\n\n\n\n\n\nCode\nasia = world |&gt; \n  filter(continent == \"Asia\", !is.na(iso_a2)) %&gt;% \n  dplyr::rename(Country = name_long) %&gt;%\n  right_join(urban_pop_asia, by = \"Country\") %&gt;% \n  # dplyr::select(name, subregion, gdpPercap, HDI, pop_growth, urban_pop) %&gt;% \n  st_transform(\"+proj=aea +lat_1=20 +lat_2=-23 +lat_0=0 +lon_0=25\")\n\n\nasia_map&lt;- ggplot(asia) +\n  geom_sf() +\n  theme_bw()\n \nurban_map_asia &lt;- ggplot(asia) +\n  # geom_sf(aes(color) = HDI)) +\n  geom_sf(aes(fill = Urban_population)) +\n  theme_bw() \n\nasia_map+urban_map_asia\n\n\n\n\n\nAsia Urban Population\n\n\n\n\n\n\nCode\namerica = world |&gt; \n  filter(continent == \"America\", !is.na(iso_a2)) %&gt;% \n  dplyr::rename(Country = name_long) %&gt;%\n  right_join(urban_pop_america, by = \"Country\") %&gt;% \n  # dplyr::select(name, subregion, gdpPercap, HDI, pop_growth, urban_pop) %&gt;% \n  st_transform(\"+proj=aea +lat_1=20 +lat_2=-23 +lat_0=0 +lon_0=25\")\n\n\namerica_map&lt;- ggplot(america) +\n  geom_sf() +\n  theme_bw()\namerica_map  \nurban_map_america &lt;- ggplot(america) +\n  # geom_sf(aes(color) = HDI)) +\n  geom_sf(aes(fill = Urban_population)) +\n  theme_bw() \n\namerica_map+urban_map_america\n\n\n\n\n\nAmericas Urban Population\n\n\n\n\n\n\n\nAgricultural Water Withdrawls and GDP\nWater stress is defined based on the ratio of freshwater withdrawals to renewable freshwater resources. Water stress does not insinuate that a country has water shortages, but does give an indication of how close it maybe be to exceeding a water basin‚Äôs renewable resources. If water withdrawals exceed available resources (i.e.¬†greater than 100 percent) then a country is either extracting beyond the rate at which aquifers can be replenished, or has very high levels of desalinisation water generation (the conversion of seawater to freshwater using osmosis processes).\nBefore Running the linear regression model, I plotted the agricultural water withdrawal versus GDP per capital. I figured that GDP is could be an indicator of urbanization.\n\n\nCode\nggplot(data = urban_pop_asia, aes(x = GDP, y = `Agricultural Water Withdrawal`)) +\n  geom_point() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +  # Adjust the angle as needed\n  geom_text(aes(label = Country), vjust = -0.5, hjust = 1) +  # Adjust vjust and hjust as needed\n  labs(title = \"Agricultural water withdrawals vs. GDP per capita, 2019\",\n       x = \"GDP per Capita\",\n       y = \"Annual freshwaer withdrawals, agricuture(% of total freshwater withdrawl)\") +\n  theme_minimal()\n\n\n\n\n\nAgricultural water withdrawals vs.¬†GDP per capita, 2019\n\n\nThis premilniary plot shows that opposite of my prediction‚Äìthat increased GDP would increase agricultural water withdrawal. Overall, we see a negative correlation: agriculture‚Äôs share of total water withdrawals tend to decrease at higher incomes.\nThe Asian LIFD countries in the plot(clustered around the upper left of the plot) used more water for agriculture.\n\n\n\nAnalysis - Linear Regression\n\nRelationship Between Urban Population and Water Stress in Asia\nFor this analysis I ran a linear regression to see if there was some relationship between urban population and water stress. From previous knowledge, we can expect the highter the urban population, the more water stress we can expect. An increase in urban populations might exasperate water withrawals in cities. Droughts may be exasperated in more urban areas due to increase temperatures from urbanization, transportions,\n\n\nCode\nwater_select &lt;- water1 %&gt;% \n  select(c(\"SDG 6.4.2. Water Stress_%\",\"Urban population_1000 inhab\", \"Country\")) %&gt;% \n  mutate(`Urban population_1000 inhab` = as.numeric(`Urban population_1000 inhab`)) %&gt;% \n  mutate(`SDG 6.4.2. Water Stress_%` = as.numeric(`SDG 6.4.2. Water Stress_%`))\n\nwater_select\nwater_stress_lm &lt;- lm(` Water Stress_%` ~ `Urban population_1000 inhab`, data = water_select)\nsummary(water_stress_lm)\n\n\n\n\n\nLinear Model\n\n\nThe linear model used here does not conclude to a definite conclusion. The R-squared measurement of 2.7%. This was to be expected. From the EDA step, we saw a negative correlation between Agricultural water withdrawal and GDP. GDP is a fair indicator of urbanization therefore a low r-squared value seems to be on the right track.\n\n\n\nAnalysis - Time Series of Freshwater Withdrawls (Asia)\nHere, I atttempted to use a Time Series of the Freshwater and Municipial water withdrawals.\nIrrigation water withdrawal normally far exceeds the net irrigation water requirement because of water lost in its distribution from its source to the crops.\nAssessing the impact of irrigation on water resources requires an estimate of the water effectively withdrawn for irrigation, i.e.¬†the volume of water extracted from rivers, lakes and aquifers for irrigation purposes\n\n\nCode\nannual_freshwawter_withdrawls$Year &lt;- as.Date(AirPassengers$Year)\n\n# Create a time series plot\nts_annual_freshwater &lt;- annual_freshwawter_withdrawls %&gt;% \n  group_by(Year) %&gt;% \n  ggplot( aes(x = Year, y = `Annual freshwater withdrawals, total (billion cubic meters)`, color = Entity)) +\n  geom_point() +\n  labs(title = \"Annual freshwater withdrawals, 1975 to 2019\",\n       x = \"Year\",\n       y = \"total water withdrawalin cubic metres (m¬≥) per year\")\nts_annual_freshwater \n\n\n\n\n\nFresh Water Withdrawal 1975 - 2019, Asia\n\n\nInterpretation I chose Asian countries becuase it was the easiest to visualize in one plot. We can see that there is missing data for many countries up until 1995, therefore it makes for a\n\n\nAnalysis - Time Series of Municipial Water Withdrawals (Asia)\nMunicipal water withdrawal\nTotal water withdrawal for municipal (domestic) purposes, measured in cubic metres (m¬≥) per year. Municipal water is the annual quantity of water withdrawn primarily for the direct use by the population.\n\n\nCode\nannual_minicipial_withdrawls$Year &lt;- as.Date(AirPassengers$Year)\n\n# Create a time series plot\nts_annual_municipial &lt;- annual_minicipial_withdrawls %&gt;% \n  group_by(Year) %&gt;% \n  ggplot( aes(x = Year, y = `Annual municipial withdrawals, total (billion cubic meters)`, color = Entity)) +\n  geom_point() +\n  labs(title = \"Annual minicipial withdrawals, 1975 to 2019\",\n       x = \"Year\",\n       y = \"total water withdrawalin cubic metres (m¬≥) per year\")\nts_annual_freshwater \n\n\n\n\n\nMunicipial Water Withdrawl from 1970 to 2015,Asia\n\n\nInterpretation I chose Asian countries becuase it was the easiest to visualize in one plot. We can see that there is missing data for many countries up until 1995. I Also omitted India, because if it outlying measurements.\n\n\nSummary\nWater scarcity is a growing concern in vulnerable countries that have predisposed risks due to climate change. Understanding the causes of these stressors‚Äìwhether it be industrial, municipal or agricultural‚Äìis a step in the right direction to mitigate water scarcity. This project worked as a preliminary analysis to understand which stressor is most affecting LIFDCs. I focused on urbanization due to the fact that urban centers are a key part of a country‚Äôs development. As LIFDCs work their way out of this label, urbanization will be key part in a populations climb from rural to urban. From the linear regression model, we can concluded that the relationship between urban population and water stress is inconclusive. There are other factors that affect water stress.\n\n\nLimitations and Next Steps\nThere is a lot of missing data for LIFDCs due to privatized water management systems and low resources. These countries also face violations to water rights therefore data is scarce and not published due to fear. The next steps would be a further investigation to missing data. A key part of water knowledge would be community based knowledge, although this analysis project may need to be scaled down.\n\n\nReferences\nHannah Ritchie and Max Roser (2018)-‚ÄúWater Use and Stress‚Äù Published online at OurWorldInData.org. Retrieved from: ‚Äòhttps://ourworldindata.org/water-use-stress‚Äô [Online Resource]\n(2021)-‚ÄúAQUASTAT - FAO‚Äôs Global Information System on Water and Agriculture‚Äù Published online at www.fao.org. Retrieved from: ‚Äòhttps://www.fao.org/aquastat/en/data-analysis/irrig-water-use/‚Äô [Online Resource]\n(2021)-‚ÄúAQUASTAT Dissemination System‚Äù Published online at www.fao.org. Retrieved from: ‚Äòhttps://data.apps.fao.org/aquastat/?lang=en‚Äô [Online Resource]\n\n\n\n\nCitationBibTeX citation:@online{salgado2023,\n  author = {Salgado, Vanessa},\n  title = {Water {Stressors} for {Low} {Income} {Food} {Deficit}\n    {Countries}},\n  date = {2023-12-15},\n  url = {https://github.com/Vanessa-Salgado},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nSalgado, Vanessa. 2023. ‚ÄúWater Stressors for Low Income Food\nDeficit Countries.‚Äù December 15, 2023. https://github.com/Vanessa-Salgado."
  },
  {
    "objectID": "posts/2023-12-15-water-stress/index.html#background-and-motivation",
    "href": "posts/2023-12-15-water-stress/index.html#background-and-motivation",
    "title": "Water Stressors for Low Income Food Deficit Countries",
    "section": "",
    "text": "Water is the worlds most valuable resource and climate change will likely exacerbate water stress world wide. Water stress will further affect the most vulnerable countries. Vulnerable countries are already facing water shortages, poor water management, privatized water management, etc. Water stressors include demands from agriculture, natural disasters, industrial use , and municipal use. Water stress occurs when demand for safe, usable water in a given area exceeds the supply. I thought a good measure of vulnerability would be to study water stressors in Low income food deficit countries(LIFDCs) given that vulnerable countries often face issues of poverty and food scarcity that are often linked to water vulnerability.\nIn this study I chose to focus on the most vulnerable areas for certain reasons\na. challenge myself with missing data\nb. stray away from Eurocentric studies that focus on Western development\nc.¬†Highlight countries of need\nd."
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "Vanessa Salgado",
    "section": "",
    "text": "Hi! My name is Vanessa Salgado."
  },
  {
    "objectID": "posts/2023-12-15-texas/index.html#how-did-socioeconomic-factors-influence-community-recovery-from-2021-power-outages-in-houston",
    "href": "posts/2023-12-15-texas/index.html#how-did-socioeconomic-factors-influence-community-recovery-from-2021-power-outages-in-houston",
    "title": "2021 Texas Blackout",
    "section": "How did socioeconomic factors influence community recovery from 2021 power outages in Houston?",
    "text": "How did socioeconomic factors influence community recovery from 2021 power outages in Houston?\nüì¶ repo link | https://github.com/Vanessa-Salgado/houston-blackout-lights-analysis\n\nBackground\nIn February 2021, severe winter storms in the United States caused a major power outage in the state of Texas. The loss of power resulted in over 4.5 million homes and businesses left without power, and several deaths. This analysis uses remotely sensed night light data to assess the impact and distribution of these blackouts. Data from the U.S. Census Bureau will be added to investigate if socioeconomic factors affect the recovery of power within the community.\n\n\nProject objectives and methods\nIn this analysis, I will be: - estimating the number of homes in Houston that lost power as a result of the first two storms\n- investigating if socioeconomic factors are predictors of communities recovery from a power outage\nThis analysis will rely on remotely-sensed night lights data acquired from the Visible Infrared Imaging Radiometer Suite (VIIRS) aboard the Suomi satellite. Specifically, we will use the VNP46A1 to identify variations in night lights before and after the storms as a method to identify areas that lost electrical power."
  },
  {
    "objectID": "posts/2023-12-15-texas/index.html#data",
    "href": "posts/2023-12-15-texas/index.html#data",
    "title": "2021 Texas Blackout",
    "section": "Data",
    "text": "Data\n\nNight lights\nWe use NASA‚Äôs Worldview to explore the data around the day of the storm. There are several days with too much cloud cover to be useful, but 2021-02-07 and 2021-02-16 provide two clear, contrasting images to visualize the extent of the power outage in Texas.\nVIIRS data is distributed through NASA‚Äôs Level-1 and Atmospheric Archive & Distribution System Distributed Active Archive Center (LAADS DAAC). Many NASA Earth data products are distributed in 10x10 degree tiles in sinusoidal equal-area projection. Tiles are identified by their horizontal and vertical position in the grid. Houston lies on the border of tiles h08v05 and h08v06. We therefore need to download two tiles per date.\n\n\nRoads gis_osm_roads_free_1.gpkg\nTypically highways account for a large portion of the night lights observable from space (see Google‚Äôs Earth at Night). To minimize falsely identifying areas with reduced traffic as areas without power, we will ignore areas near highways.\nOpenStreetMap (OSM) is a collaborative project which creates publicly available geographic data of the world. We used Geofabrik‚Äôs download sites to retrieve a shapefile of all highways in Texas and prepared a Geopackage (.gpkg file) containing just the subset of roads that intersect the Houston metropolitan area.¬†\n\n\nHouses gis_osm_buildings_a_free_1.gpkg\nWe also obtain building data from OpenStreetMap. We again downloaded from Geofabrick and prepared a GeoPackage containing only houses in the Houston metropolitan area.\n\n\nSocioeconomicACS_2019_5YR_TRACT_48.gdb\nWe cannot readily get socioeconomic information for every home, so instead we obtained data from the U.S. Census Bureau‚Äôs American Community Survey for census tracts in 2019. The folder ACS_2019_5YR_TRACT_48.gdb is an ArcGIS ‚Äúfile geodatabase‚Äù, a multi-file proprietary format that‚Äôs roughly analogous to a GeoPackage file. We can use st_layers() to explore the contents of the geodatabase. Each layer contains a subset of the fields documents in the ACS metadata. The geodatabase contains a layer holding the geometry information, separate from the layers holding the ACS attributes. You have to combine the geometry with the attributes to get a feature layer that sf can use."
  },
  {
    "objectID": "posts/2023-12-15-texas/index.html#outline-and-plan-of-analysis",
    "href": "posts/2023-12-15-texas/index.html#outline-and-plan-of-analysis",
    "title": "2021 Texas Blackout",
    "section": "Outline and Plan of Analysis",
    "text": "Outline and Plan of Analysis\nBelow is an outline of the steps taken to achieve the objectives.\n1) Find locations of blackouts\n2) Find homes impacted by blackouts\n3) Investigate Socioeconomic Factors\n4) Leverage the results for a summary and discussion"
  },
  {
    "objectID": "posts/2023-12-15-texas/index.html#importing-necessary-libraries-and-functions",
    "href": "posts/2023-12-15-texas/index.html#importing-necessary-libraries-and-functions",
    "title": "2021 Texas Blackout",
    "section": "Importing necessary libraries and functions",
    "text": "Importing necessary libraries and functions\n\n\nCode\nlibrary(sf)\nlibrary(stars)\nlibrary(tmap)\nlibrary(raster)\nlibrary(terra)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(here)"
  },
  {
    "objectID": "posts/2023-12-15-texas/index.html#find-locations-of-blackouts",
    "href": "posts/2023-12-15-texas/index.html#find-locations-of-blackouts",
    "title": "2021 Texas Blackout",
    "section": "Find locations of blackouts",
    "text": "Find locations of blackouts\nFor improved computational efficiency and easier inter-operability with sf, we use the stars package for raster handling.\n\nCombining the data\nWe first read in night lights tiles, then combine tiles into a single stars object for each date (2021-02-07 and 2021-02-16) using st_mosaic.\nThe following files had been subsetted & stored in the VNP46A1 folder.\n\nVNP46A1.A2021038.h08v05.001.2021039064328.tif: tile h08v05, collected on 2021-02-07\nVNP46A1.A2021038.h08v06.001.2021039064329.tif: tile h08v06, collected on 2021-02-07\nVNP46A1.A2021047.h08v05.001.2021048091106.tif: tile h08v05, collected on 2021-02-16\nVNP46A1.A2021047.h08v06.001.2021048091105.tif: tile h08v06, collected on 2021-02-16\n\n\n\nCreating a blackout mask\nWe then find the change in night lights intensity (presumably) caused by the storm, and reclassify the difference raster, assuming that any location that experienced a drop of more than 200 nW cm-2sr-1 experienced a blackout. Then we assign NA to all locations that experienced a drop of less than 200 nW cm-2sr.-1\n\n\n\nCode\n#find the change in night lights intensity (presumably) caused by the storm by calculating the light difference between the two dates \ndifference &lt;- combined_02_07 - combined_02_16\n\n\n#check out difference in night lights intensity \nplot(difference)\n\n\ndownsample set to 6\n\n\n\n\n\nAssigning all the houses that experienced a drop of 200 and more to a blackout mask.\n\n\nCode\nmask_blackout &lt;- difference &gt; 200 \nmask_blackout[mask_blackout == FALSE]  &lt;- NA\n\n\n\n\nVectorize the mask\nWe use st_as_sf() to vectorize the blackout mask and fix any invalid geometries using st_make_valid.\n\n\nCode\nblackout_mask_vector &lt;- st_as_sf(mask_blackout) %&gt;% st_make_valid() ##can plot() to check out what the blackout mask looks like \n\n\n\n\nCropping the vectorized map to our region of interest\n\nWe first define the Houston metropolitan area with the following coordinates : (-96.5, 29), (-96.5, 30.5), (-94.5, 30.5), (-94.5, 29) and then turn these coordinates into a polygon using st_polygon.\nThen we convert the polygon into a simple feature collection using st_sfc() and assign a CRS, making sure that the polygon is in the same CRS and crop (spatially subset) the blackout mask to our region of interest. Lastly we re-project the cropped blackout dataset to EPSG:3083 (NAD83 / Texas Centric Albers Equal Area).\n\n\n\n\nCode\n#crop the vectorized map to our region of interest using polygon of Houston's coordinates \nhouston_polygon &lt;- st_polygon(list(rbind(c(-96.5,29), c(-96.5,30.5), c(-94.5, 30.5), c(-94.5,29), c(-96.5,29))))\n\n\n#convert the polygon into a simple feature collection using st_sfc() and assign the CRS 4326, which is the same as the night lights data\nhouston_border_sf &lt;- st_sfc(houston_polygon, crs = st_crs(mask_blackout))\n\n\n#inspect the polygon crs to make sure the crs is 4326, nightlights dataset\n#st_crs(houston_border_sf) == st_crs(mask_blackout)\n\n\nSpatially subsetting blackout mask to Houston region, then reprojecting to the correct CRS.\n\n\nExcluding highways from blackout mask\nThe roads geopackage includes data on roads other than highways. However, we can avoid reading in data we don‚Äôt need by taking advantage of st_read‚Äôs ability to subset using a SQL query. First, we load just highway data from geopackage using st_read andreproject data to EPSG:3083, identifying areas within 200m of all highways using st_buffer. st_buffer produces undissolved buffers, so we use st_union to dissolve them. Then we find areas that experienced blackouts that are further than 200m from a highway.\nRead in highway data from roads using SQL query :\nquery &lt;- \"SELECT * FROM gis_osm_roads_free_1 WHERE fclass='motorway'\"\nhighways &lt;- st_read(\"data/gis_osm_roads_free_1.gpkg\", query = query)\n\n\nCode\nquery &lt;- \"SELECT * FROM gis_osm_roads_free_1 WHERE fclass='motorway'\"\nhighways &lt;- st_read(here(\"data/gis_osm_roads_free_1.gpkg\"), query = query)\n\n\nThen reproject and subset using st_difference()\n\n\nCode\n# reproject data to EPSG:3083 \nhighways_3038 &lt;- st_transform(highways, crs=\"EPSG:3083\")\n\n#verify it's the right crs\n#st_crs(highways_3038)\n\n# identify areas within 200m of all highways using st_buffer. Use st_union to dissolve overlapping polygons. \na_near_hwys &lt;- st_buffer(highways_3038, dist = 200) %&gt;% st_union()\n\n# find areas that experienced blackouts that are further than 200m from a highway by spacially subsetting houston blackout areas to ones near highways, and taking st_difference of that. \nblackouts_far_hwy_houston &lt;- final_houston_blackout[a_near_hwys, , op = st_difference] \n\n\n#plot to see what it looks like \n#plot(blackouts_far_hwy_houston)"
  },
  {
    "objectID": "posts/2023-12-15-texas/index.html#finding-homes-impacted-by-blackouts",
    "href": "posts/2023-12-15-texas/index.html#finding-homes-impacted-by-blackouts",
    "title": "2021 Texas Blackout",
    "section": "Finding homes impacted by blackouts",
    "text": "Finding homes impacted by blackouts\n\nLoad buildings data\nWe load buildings dataset using st_read and the following SQL query to select only residential buildings. We first reproject data to EPSG:3083.\nThe SQL query we will use is:\nSELECT *¬† FROM gis_osm_buildings_a_free_1\nWHERE (type IS NULL AND name IS NULL)\nOR type in ('residential', 'apartments', 'house', 'static_caravan', 'detached')\n\n\n\nCode\n#load buildings dataset using st_read and the following SQL query to select only residential buildings\n\nquery_buildings &lt;- \"SELECT * FROM gis_osm_buildings_a_free_1 WHERE (type IS NULL AND name IS NULL) OR type in ('residential', 'apartments', 'house', 'static_caravan', 'detached')\"\n\nbuildings &lt;- st_read(here(\"data\",\"gis_osm_buildings_a_free_1.gpkg\"), query = query_buildings)\n\n\n\n\nfinding homes in blackout areas\nWe filter to homes within blackout areas, then we count number of impacted homes. First, checking for CRS compatibility. Since they aren‚Äôt, we need to transform and then subset.\n\n\nCode\n##check CRS's are the same. No, they're not!\n#st_crs(buildings) == st_crs(blackouts_far_hwy_houston)\n\n##transform buildings crs \nbuildings &lt;- st_transform(buildings, crs = st_crs(blackouts_far_hwy_houston))\n\n# filtering the houses data with the blackout mask\nbuildings_blackout &lt;- buildings[blackouts_far_hwy_houston, drop = FALSE]\n\n## View the data frame for inspection \n#View(buildings_blackout)\n\n#count number of impacted homes\nprint(paste0(nrow(buildings_blackout), \" Houston homes experienced power outage due to the Texas storms in Feburary, 2021\"))\n\n\n[1] \"164867 Houston homes experienced power outage due to the Texas storms in Feburary, 2021\""
  },
  {
    "objectID": "posts/2023-12-15-texas/index.html#investigate-socioeconomic-factors",
    "href": "posts/2023-12-15-texas/index.html#investigate-socioeconomic-factors",
    "title": "2021 Texas Blackout",
    "section": "Investigate socioeconomic factors",
    "text": "Investigate socioeconomic factors\n\nload ACS data\nTo set up for loading, we use st_read() to load the geodatabase layers and geometries are stored in the ACS_2019_5YR_TRACT_48_TEXAS layer. The income data is stored in the X19_INCOME layer, so we select the median income field B19013e1 andreproject data to EPSG:3083.\n\n\nDetermine which census tracts experienced blackouts\nWe join the income data to the census tract geometries by joining by geometry ID and spatially join census tract data with buildings determined to be impacted by blackouts, then find which census tracts had blackouts.\n\n\n\nCode\n#determine which census tracts experienced blackouts \n#Join the income data to the census tract geometries. Join by geometry ID\nmedian_income_df &lt;- median_income %&gt;% rename(GEOID_Data = GEOID,\n         median_income = B19013e1) \n\n\n##check types to varify that they are the same class \n#class(median_income_df$GEOID_Data) == class(census$GEOID_Data)\n\njoined_income_census &lt;- left_join(census, \n                         median_income_df, \n                         by = \"GEOID_Data\")\n\n\n## filter census data by buildings determined to be impacted by blackouts. \n\n# transforming both objects to the correct crs\njoined_income_census &lt;- st_transform(joined_income_census, crs = st_crs(census))\nbuildings_blackout &lt;- st_transform(buildings_blackout, crs = st_crs(census))\n\n#check that they are the same crs \n#st_crs(joined_income_census) == st_crs(buildings_blackout)\n\n## filtering and mutating to add a blackout column for affected tracts \ncensus_blackout &lt;- joined_income_census[buildings_blackout,]%&gt;% mutate(blackout = 'Y')\n\nprint(paste0(nrow(census_blackout), \" census tracts had blackouts\"))\n\n\n[1] \"778 census tracts had blackouts\"\n\n\nSince we have blackout status of Y indicated, we will want to indicate ‚ÄúN‚Äù for no-blackout areas as well, for full dataset.\n\n\nComparing incomes of impacted tracts to unimpacted tracts\nTo do this, we create a map using tmap of median income by census tract, designating which tracts had blackouts. We then plot the distribution of income in impacted and unimpacted tracts.\nI included the code for the map here, although the map does not render. I‚Äôve attached a screeshot\n\n\nCode\n#join income data to the census tract geometries and crop to region of interest\ncensus_income_geom &lt;- left_join(census, median_income_df, \n                         by = \"GEOID_Data\") %&gt;% st_transform(3083) #this is texas#\nhouston_border_sf &lt;- houston_border_sf %&gt;% st_transform(3083)\n\n\n#spatial crop joined census data to houston border \ncensus_income_geom_cropped &lt;- census_income_geom[houston_border_sf, op = st_intersects] \n\n\n## use tmap to plot income distribution and affected areas. Make graph aesthetics. \n# tmap_mode(\"plot\")\n# tm_shape(census_income_geom_cropped) + \n#   tm_graticules() + \n#   tm_polygons(\"median_income\", palette= \"-viridis\", title = \"Median Income\") + \n#   tm_shape(census_blackout) + tm_dots(size = 0.4, alpha = 0.5) + \n#   tm_title( \"Blackout Status & Median Income by Census in Houston (Feb 16,2021)\") +\n#   tm_scalebar(position = c(\"RIGHT\", \"BOTTOM\")) + \n#   tm_compass(position = c(\"LEFT\", \"TOP\")) + \n#   tm_xlab(\"Longitude\", size = 0.5) + \n#   tm_ylab(\"Latitude\", rotation = 90, size = 0.5)"
  },
  {
    "objectID": "posts/2023-12-15-texas/index.html#discussion",
    "href": "posts/2023-12-15-texas/index.html#discussion",
    "title": "2021 Texas Blackout",
    "section": "Discussion",
    "text": "Discussion\nWe found that 778 census tracts had been affected by Texas‚Äôs 2021 energy crisis, amounting to 164,867 total homes experiencing power outage between the studied dates (Feb 07, 2021 to Feb 16, 2021).\nThe average median income for homes that experienced a blackout was $70,939, slightly higher than the average median income for homes that didn‚Äôt experience a blackout, which was $67,859. It is important to note that 1) our factor of interest was median income within census tracts and that other socioeconomic factors could reveal unexplored spatial patterns, and that 2) weather conditions were not normalized to conduct this exercise, variable that could cause a different outcome."
  },
  {
    "objectID": "posts/2023-12-15-texas/index.html#references",
    "href": "posts/2023-12-15-texas/index.html#references",
    "title": "2021 Texas Blackout",
    "section": "References",
    "text": "References\n[1] Ball, J. (Feb, 2021). The Texas Blackout is the Story of a Disaster Foretold. Texas Monthly. URL: https://www.texasmonthly.com/news-politics/texas-blackout-preventable/\n[2] Henson, Bob. (Feb, 2021). Why the power is out in Texas‚Ä¶ and why other states are vulnerable too. Yale Climate Connections. URL: https://yaleclimateconnections.org/2021/02/why-the-power-is-out-in-texas-and-why-other-states-are-vulnerable-too/\n[3] Irfan, U. (Mar, 2021). Why every state is vulnerable to a Texas-style power crisis. Vox. URL: https://www.vox.com/22308149/texas-blackout-power-outage-winter-uri-grid-ercot\n[4] National Center for Disaster Preparedness (NCDP). (Mar, 2023). Disaster Response and Equity: Reflecting on the Racial Disparities in Texas Power Outages. URL: https://ncdp.columbia.edu/ncdp-perspectives/disaster-response-and-equity-texas-power-outrages/"
  },
  {
    "objectID": "posts/2023-12-15-texas/index.html#question-how-did-socioeconomic-factors-influence-community-recovery-from-2021-power-outages-in-houston-texas",
    "href": "posts/2023-12-15-texas/index.html#question-how-did-socioeconomic-factors-influence-community-recovery-from-2021-power-outages-in-houston-texas",
    "title": "2021 Texas Blackout",
    "section": "Question: How did socioeconomic factors influence community recovery from 2021 power outages in Houston, Texas?",
    "text": "Question: How did socioeconomic factors influence community recovery from 2021 power outages in Houston, Texas?\nrepo link | https://github.com/Vanessa-Salgado/houston-blackout-lights-analysis\n\nBackground\nIn February 2021, severe winter storms in the United States caused a major power outage in the state of Texas. The loss of power resulted in over 4.5 million homes and businesses left without power, and several deaths. This analysis uses remotely sensed night light data to assess the impact and distribution of these blackouts. Data from the U.S. Census Bureau will be added to investigate if socioeconomic factors affect the recovery of power within the community.\n\n\nProject objectives and methods\nIn this analysis, I will be: - estimating the number of homes in Houston that lost power as a result of the first two storms\n- investigating if socioeconomic factors are predictors of communities recovery from a power outage\nThis analysis will rely on remotely-sensed night lights data acquired from the Visible Infrared Imaging Radiometer Suite (VIIRS) aboard the Suomi satellite. Specifically, we will use the VNP46A1 to identify variations in night lights before and after the storms as a method to identify areas that lost electrical power."
  },
  {
    "objectID": "posts/2024-03-14-carbon-data-viz/index.html",
    "href": "posts/2024-03-14-carbon-data-viz/index.html",
    "title": "Carbon Credits Data Visualization",
    "section": "",
    "text": "The Paris Agreement of 2015 was an international standard laid out in order to reduce \\(CO_2\\) emissions. With the Paris Aggreement, national emmisions target and regulations sprung up in order to substantially reduce global greenhouse gas emmission to hold global temperature incear to well below 2 C.\nWith these new regulations, businesses were pressured to lower their emmissions. Thuse introducing carbon markets with the promise to turn \\(CO_2\\) into a commodity.\nCarbon offsetting is a trading mechanism that allows entities such as governments, individuals, or businesses to compensate for their greenhouse gas emissions by supporting projects that reduce, avoid, or remove emissions elsewhere.\nTo Put it simply, carbon offsets involve an entity that emits greenhouse gases into the atmosphere paying for another entity to pollute less. For example, an airline in a developed country that wants to claim it is reducing its emissions can pay for a patch of rainforest to be protected in the Amazon.\nThe main research question I want to investigate is whether carbon credits are an effective way to measure carbon offset emissions. Each credit purportedly offsets a metric tonne of CO2 emissions, yet the Berkeley Carbon Trading Project reports that, ‚Äúresearch performed by [them] and others has found that many, if not most, offset credits traded on the market today do not represent real emissions reductions.‚Äù [[^1]]"
  },
  {
    "objectID": "posts/2024-03-14-carbon-data-viz/index.html#background-and-motivation-star",
    "href": "posts/2024-03-14-carbon-data-viz/index.html#background-and-motivation-star",
    "title": "Carbon Credits Data Visualization",
    "section": "Background and Motivation :star:",
    "text": "Background and Motivation :star:\n:star: The Paris Agreement of 2015 was an international standard laid out in order to reduce \\(CO_2\\) emissions. With the Paris Aggreement, national emmisions target and regulations sprung up in order to substantially reduce global greenhouse gas emmission to hold global temperature incear to well below 2 C.\nWith these new regulations, businesses were pressured to lower their emmissions. Thuse introducing carbon markets with the promise to turn \\(CO_2\\) into a commodity.\nCarbon offsetting is a trading mechanism that allows entities such as governments, individuals, or businesses to compensate for their greenhouse gas emissions by supporting projects that reduce, avoid, or remove emissions elsewhere.\nTo Put it simply, carbon offsets involve an entity that emits greenhouse gases into the atmosphere paying for another entity to pollute less. For example, an airline in a developed country that wants to claim it is reducing its emissions can pay for a patch of rainforest to be protected in the Amazon.\nThe main research question I want to investigate is whether carbon credits are an effective way to measure carbon offset emissions. Each credit purportedly offsets a metric tonne of CO2 emissions, yet the Berkeley Carbon Trading Project reports that, ‚Äúresearch performed by [them] and others has found that many, if not most, offset credits traded on the market today do not represent real emissions reductions.‚Äù [[^1]]"
  },
  {
    "objectID": "posts/2024-03-14-carbon-data-viz/index.html#goal",
    "href": "posts/2024-03-14-carbon-data-viz/index.html#goal",
    "title": "Carbon Credits Data Visualization",
    "section": "Goal",
    "text": "Goal\nCombining the Voluntary Registry Offsets Data with another emissions data would be a helpful way to measure if carbon trading/offsets are accurate in measuring emissions.\n\nReserach Questions\n\nThe main research question is to see : Are climate credits being distrubuted evenly?\n\nI will create three separate visualizations that same overall question: How has the Carbon Market grown over the years per country ? and are they keeping up with the global emission reduction goals\nEach visualization below has been"
  },
  {
    "objectID": "posts/2024-03-14-carbon-data-viz/index.html#data",
    "href": "posts/2024-03-14-carbon-data-viz/index.html#data",
    "title": "Carbon Credits Data Visualization",
    "section": "Data",
    "text": "Data\n\nLink to (or otherwise prove the existence of) at least one data set that you plan to use for Assignment #4\n\nBerkeley Voluntary Registry Offsets Database: contains all carbon offset projects, credit issuances, and credit retirements listed globally by four major voluntary offset project registries\nData on CO2 and Greenhouse emissions by Our World in Data\nRaster Data provided by Natural Earth\n\n\n\n\nCode\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                           library setup                                 ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(ggExtra)\nlibrary(gghighlight)\nlibrary(janitor)\nlibrary(naniar)\nlibrary(RColorBrewer)\nlibrary(here)\nlibrary(forcats)\n\nlibrary(showtext)\nfont_add_google(name = \"Merriweather\", family = \"merriweather\")\nfont_add_google(name = \"Karla\", family = \"karla\")\n\nfont_add(family = \"fa-6-brands\",\n         regular = here::here(\"fonts\", \"Font Awesome 6 Brands-Regular-400.otf\"))\nfont_add(family = \"fa-6-regular\",\n         regular = here::here(\"fonts\", \"Font Awesome 6 Free-Regular-400.otf\")) \nfont_add(family = \"fa-6-solid\",\n         regular = here::here(\"fonts\", \"Font Awesome 6 Free-Solid-900.otf\"))\n\nfont_add(family = \"fa-brands\",\n         regular = here::here(\"fonts\", \"fa-brands-400.ttf\"))\nfont_add(family = \"fa-regular\",\n         regular = here::here(\"fonts\", \"fa-regular-400.ttf\")) \nfont_add(family = \"fa-solid\",\n         regular = here::here(\"fonts\", \"fa-solid-900.ttf\"))\n\n\nlibrary(raster)\nlibrary(countrycode)\n\nlibrary(ggtext)\nlibrary(ggrepel)\nlibrary(patchwork)\nlibrary(systemfonts)\n\nlibrary(fmsb)\nlibrary(stringr)\n\nlibrary(emojifont)\nlibrary(NatParksPalettes)\n\nlibrary(waffle)"
  },
  {
    "objectID": "posts/2024-03-14-carbon-data-viz/index.html#data-cleaning",
    "href": "posts/2024-03-14-carbon-data-viz/index.html#data-cleaning",
    "title": "Carbon Credits Data Visualization",
    "section": "Data Cleaning",
    "text": "Data Cleaning\n\n\nCode\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                           library setup                                 ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(ggExtra)\nlibrary(gghighlight)\nlibrary(janitor)\nlibrary(naniar)\nlibrary(RColorBrewer)\nlibrary(here)\nlibrary(forcats)\n\nlibrary(showtext)\n\nfont_add_google(name = \"Ultra\", family = \"ultra\")\nfont_add_google(name = \"Josefin Sans\", family = \"josefin\")\nfont_add_google(name = \"Merriweather\", family = \"merriweather\")\nfont_add_google(name = \"Karla\", family = \"karla\")\n\nfont_add(family = \"fa-6-brands\",\n         regular = here::here(\"fonts\", \"Font Awesome 6 Brands-Regular-400.otf\"))\nfont_add(family = \"fa-6-regular\",\n         regular = here::here(\"fonts\", \"Font Awesome 6 Free-Regular-400.otf\")) \nfont_add(family = \"fa-6-solid\",\n         regular = here::here(\"fonts\", \"Font Awesome 6 Free-Solid-900.otf\"))\n\nfont_add(family = \"fa-brands\",\n         regular = here::here(\"fonts\", \"fa-brands-400.ttf\"))\nfont_add(family = \"fa-regular\",\n         regular = here::here(\"fonts\", \"fa-regular-400.ttf\")) \nfont_add(family = \"fa-solid\",\n         regular = here::here(\"fonts\", \"fa-solid-900.ttf\"))\n\n# frog icons ----\nblack_leaf &lt;- here(\"images\", \"black-leaf.jpg\")\ngreen_leaf &lt;- here(\"images\", \"green-leaf.png\")\n\n\nlibrary(raster)\nlibrary(countrycode)\n\nlibrary(ggtext)\nlibrary(ggrepel)\nlibrary(patchwork)\nlibrary(systemfonts)\n\nlibrary(fmsb)\nlibrary(stringr)\n\nlibrary(emojifont)\nlibrary(NatParksPalettes)\n\nlibrary(waffle)\n\n\n\n\nCode\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                          data cleaning & wrangling                       ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\ncarbon_offsets_clean &lt;- carbon_offsets %&gt;%\n  janitor::clean_names(case = \"snake\") %&gt;%\n  replace_with_na_all(condition = ~.x %in% c(-99999, \"#REF!\", \"N/a\", \"N/A\", \"NA\")) %&gt;%\n\n  # change char types to ints or doubles\n  mutate(total_credits_issued = as.numeric(gsub(\",\", \"\", total_credits_issued))) %&gt;%\n  mutate(total_credits_retired = as.numeric(gsub(\",\", \"\", total_credits_retired))) %&gt;%\n  mutate(total_credits_remaining = as.numeric(gsub(\",\", \"\", total_credits_remaining))) %&gt;%\n  mutate(total_buffer_pool_deposits = as.numeric(gsub(\",\", \"\", total_buffer_pool_deposits))) %&gt;%\n  mutate(first_year_of_project = as.factor(gsub(\",\", \"\", first_year_of_project))) %&gt;%\n\n  # remove irregular year columns of the structure 2001...127\n  #select_if(~!any(grepl(\"\\\\d\", .)))\n  dplyr::select(!matches(\"\\\\d\"))\n  # select(-grep(pattern = \"^[0-9]{4}\\\\.\\\\.\\\\.[0-9]{3}$\", names(.), value = TRUE)) %&gt;%\n\nyear_of_offsets &lt;- year_of_offsets %&gt;%\n  rename(year_of_offset = year)\n\ncarbon_offsets_clean_df &lt;- carbon_offsets_clean %&gt;%\n  # join with regular year data\n  full_join(year_of_offsets, by = 'project_name',relationship = \"many-to-many\")\n\n\nAfter data cleaning, I saved the cleaned dataset so that I would not have to run the cleaning script everytime. Here I simply read in the cleaned version of this carbon_offsetsdataset.\n\n\nCode\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                          importing data                      ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\ncarbon_offsets_clean &lt;- read_csv(here(\"data\",\"carbon_offsets_clean.csv\"))\n\n# color palettes\n\nglacier = c(\"#01353D\", \"#088096\", \"#58B3C7\", \"#7AD4E4\", \"#B8FCFC\")\neverglades = c(\"#345023\", \"#596C0B\", \"#83A102\", \"#003B68\", \"#426F86\", \"#7A712F\")\nigauzufalls = c(\"#415521\", \"#97AD3D\", \"#4C3425\", \"#7F6552\", \"#5A8093\", \"#9FBAD3\")\nolympic = c(\"#3A4330\", \"#426737\", \"#75871B\", \"#BAB97D\", \"#FDE16A\", \"#F9B40E\", \"#E88C23\", \"#A25933\")\n\n\nThis graph for the gneral audience is suppose to show the general trend of how Credits Retired and Credits Remaining has changed over time. The Kyoto Protocol in 1997 was the first time that international participation in carbon markets started to become more commonplace. A carbon credit is retired once its benefit has taken place. That means it has been used and the carbon benefit it represents has been claimed by the entity that bought it. We see that there is a bigger proportion of Carbon Credits Retired than Credits Remaining Unused. Meaning the Carbon Credits are working as usual.\n\n\nCode\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                    line plot of credits remaining                        ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\ncredits_plot &lt;- carbon_offsets_clean %&gt;% \n  group_by(year_of_offset) %&gt;% \n  summarize(credits_retired = sum(total_credits_retired, na.rm = TRUE),\n            credits_remaining = sum(total_credits_remaining, na.rm = TRUE))\n\n# Reshape the data for ggplot\ncredits_plot_long &lt;- tidyr::pivot_longer(credits_plot, \n                                          cols = c(credits_retired, credits_remaining),\n                                          names_to = \"type\", \n                                          values_to = \"credits\")\n\nggplot(credits_plot_long, aes(x = year_of_offset, y = credits, color = type)) +\n  geom_line(size=1) +\n  scale_color_manual(values = c(\"credits_retired\" = \"#95C65CFF\", \"credits_remaining\" = \"#4BA68C\")) +\n  scale_y_continuous(labels = scales::comma) +\n  theme_minimal() +\n  annotate(geom = \"text\", x = 1997, y = 50000000,\n    label = \"1997: Kyoto Protocol-Carbon markets started \\nto become more commonplace\",\n    size = 4, color = \"#232226\", hjust = \"inward\") +\n  annotate(geom = \"text\", x = 2015.25, y = 90000000,\n    label = \"2015: Paris Agreement adopted to\\nsubstantially reduce\\nglobal greenhouse gas\\nemissions which\\ncause global warming\n    \",\n    size = 4, color = \"#232226\", hjust = \"left\") +\n  annotate(geom = \"text\", x = 2022, y = 80000000,\n    label = \"2020: U.S.\\nOfficialy\\nLeaves\\nParis\\nClimate\\nAgreement\",\n    size = 4, color = \"#232226\", hjust = \"left\") +\n  geom_vline(xintercept = 1997.5, \n             linetype = \"dashed\") +\n  geom_vline(xintercept = 2020, \n             linetype = \"dashed\") +\n  geom_vline(xintercept = 2015, \n             linetype = \"dashed\") +\n  scale_x_continuous(expand = c(0, 0)) +\n  labs(x = \"Year of Offset\", y = \"Credits\", color = NULL, \n    title = \"&lt;span style='color:#95C65CFF'&gt;Carbon Credits Retired&lt;/span&gt; \\nand &lt;span style='color:#4BA68C'&gt;Carbon Credits Remaining&lt;/span&gt; \\nOver Time, 1997 - 2023\", \n       subtitle = \"Carbon credits, also known as carbon offsets, are permits that allow the owner to emit a certain\\namount of carbon dioxide or other greenhouse gases. One credit permits the emission of \\none ton of carbon dioxide or the equivalent in other greenhouse gases.\\nCarbon credit: It is the difference between the carbon emissions allowed and actually emitted carbon\") +\n  theme(\n    plot.title = element_markdown(color = \"#232226\", size = 16, face = \"bold\", family = \"merriweather\"),\n    axis.text.x = element_text(angle = 45, hjust = 1), # Adjust angle and font family here\n    legend.position = \"none\", \n    plot.subtitle = element_text(size = 11, face = \"plain\", color = \"#555459\", family = \"karla\"),\n    plot.caption = element_text(face = \"italic\"),\n    axis.title.x = element_text(color = \"#232226\", size = 10, angle = 0, hjust = .5, vjust = 0, face = \"bold\"),\n    axis.title.y = element_text(color = \"#232226\", size = 10, angle = 90, hjust = .5, vjust = .5, face = \"bold\"))"
  },
  {
    "objectID": "posts/2024-03-14-carbon-data-viz/index.html#second-visualization--",
    "href": "posts/2024-03-14-carbon-data-viz/index.html#second-visualization--",
    "title": "Carbon Credits Data Visualization",
    "section": "Second Visualization -",
    "text": "Second Visualization -\nThe second visualization to be included in a paper, technical documentation, or report ‚Äì this visualization should tell a similar story, but can include much more detail, more data, more domain-specific language, etc.\n\n\nCode\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                          lollipop plot of scopes                         ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\nscopes &lt;- carbon_offsets_clean %&gt;% \n  mutate(scope = as.factor(scope)) %&gt;% \n  group_by(scope) %&gt;% \n  summarize(total_credits = sum(total_credits_issued, na.rm = TRUE)) %&gt;% \n  filter(total_credits != 0)\n\nscopes_plot &lt;- ggplot(scopes) + \n  ggalt::geom_lollipop(aes( x = reorder(scope,total_credits),y = total_credits), color = \"#9BB655FF\", size = 1.5) +\n  scale_y_continuous(labels = scales::comma, expand = c(0, 0)) +\n  geom_text(aes(x = reorder(scope, total_credits), y = total_credits, label = total_credits),\n            vjust = 0.7, color = \"#232226\", size = 3, hjust = -.1) +  \n  theme_minimal() +\n  labs(title = \"Total Credits Assigned to each Project Scope\",\n       subtitle = \"Scopes refers to the type of projects that aim to reduce emissions\", \n       x = \"Project Scope Category\" ,\n       y = \"Credits Assigned to each Scope\") +\n  \n  coord_flip() +\n  # Annotate custom scale inside plot\n  theme(\n    plot.title = element_markdown(color = \"#232226\", size = 16, face = \"bold\", family = \"merriweather\", hjust = 0.5),\n        axis.text.x = element_text(angle = 45, hjust = 1, family = \"karla\"), # Adjust angle and font family here\n        axis.text.y = element_text(color = \"black\"),\n        legend.position = \"none\", \n        plot.subtitle = element_text(size = 11, face = \"plain\", color = \"#555459\", family = \"karla\", hjust = 0.5),\n        plot.caption = element_text(face = \"italic\"),\n        axis.title.x = element_text(color = \"black\", size = 10, angle = 0, hjust = .5, vjust = 0, face = \"bold\"),\n        axis.title.y = element_text(color = \"black\", size = 10, angle = 90, hjust = .5, vjust = .5, face = \"bold\"))\n\nscopes_plot"
  },
  {
    "objectID": "posts/2024-03-14-carbon-data-viz/index.html#third-visualiztion--",
    "href": "posts/2024-03-14-carbon-data-viz/index.html#third-visualiztion--",
    "title": "Carbon Credits Data Visualization",
    "section": "Third Visualiztion -",
    "text": "Third Visualiztion -\nThe third visualization that you could include in a presentation\n\n\nCode\nscopes &lt;- carbon_offsets_clean %&gt;% \n  mutate(scope = as.factor(scope)) %&gt;% \n  group_by(scope) %&gt;% \n  summarize(total_credits = sum(total_credits_issued, na.rm = TRUE)) %&gt;% \n  filter(total_credits != 0)\n  # pivot_wider(names_from = scope, values_from = total_credits) %&gt;% \n  # dplyr::select(!\"NA\")\nstr(scopes)\n\n\ntibble [9 √ó 2] (S3: tbl_df/tbl/data.frame)\n $ scope        : Factor w/ 9 levels \"Agriculture\",..: 1 2 3 4 5 6 7 8 9\n $ total_credits: num [1:9] 3.17e+07 2.18e+07 1.13e+08 7.63e+08 1.50e+08 ...\n\n\nCode\nradarchart(scopes, cglty = 1,       # Grid line type\n           cglcol = \"gray\", # Grid line color\n           cglwd = 1,       # Line width of the grid\n           pcol = 4,        # Color of the line\n           plwd = 2,        # Width of the line\n           plty = 1, \n           maxmin = FALSE)\n\n\nThe number of variables must be 3 or more.\n\n\nNULL\n\n\nCode\nunique(scopes$total_credits)\n\n\n[1]  31665959  21794661 112756177 762853289 149828673 117561615 636835826\n[8]   1418260 115805892\n\n\n\n\nCode\nplt &lt;- ggplot(scopes) + \n  # Add bars to represent the cumulative track lengths\n  # str_wrap(region, 5) wraps the text so each line has at most 5 characters\n  # (but it doesn't break long words!)\n  # geom_col(aes( x = reorder(scope,total_credits),y = total_credits), position = \"dodge2\", show.legend = TRUE, alpha = .9) +\n  ggalt::geom_lollipop(aes( x = reorder(scope,total_credits),y = total_credits), color = \"#9BB655FF\", size = 1.5) +\n  scale_y_continuous(labels = scales::comma, expand = c(0, 0)) +\n  geom_text(aes(x = reorder(scope, total_credits), y = total_credits, label = total_credits),\n            vjust = 0.7, color = \"#232226\", size = 3, hjust = -.1) +  \n  theme_minimal() +\n  labs(title = \"Total Credits Assigned to each Project Scope\",\n       subtitle = \"Scopes refers to the type of projects that aim to reduce emissions\", \n       x = \"Project Scope Category\" ,\n       y = \"Credits Assigned to each Scope\") +\n  coord_flip() +\n  # Annotate custom scale inside plot\n  theme(plot.title = element_markdown(color = \"#232226\", size = 16, , family = \"merriweather\"),\n        axis.text.x = element_text(angle = 45, hjust = 1, family = \"karla\"), # Adjust angle and font family here\n        axis.text.y = element_text(color = \"black\"),\n        legend.position = \"none\", \n        plot.subtitle = element_text(size = 11, face = \"plain\", color = \"#555459\", family = \"karla\"),\n        plot.caption = element_text(face = \"italic\"),\n        axis.title.x = element_text(color = \"black\", size = 10, angle = 0, hjust = .5, vjust = 0, face = \"bold\"),\n        axis.title.y = element_text(color = \"black\", size = 10, angle = 90, hjust = .5, vjust = .5, face = \"bold\"))\n\n\nRegistered S3 methods overwritten by 'ggalt':\n  method                  from   \n  grid.draw.absoluteGrob  ggplot2\n  grobHeight.absoluteGrob ggplot2\n  grobWidth.absoluteGrob  ggplot2\n  grobX.absoluteGrob      ggplot2\n  grobY.absoluteGrob      ggplot2\n\n\nCode\nplt\n\n\nWarning: Using the `size` aesthetic with geom_segment was deprecated in ggplot2 3.4.0.\n‚Ñπ Please use the `linewidth` aesthetic instead.\n\n\n\n\n\n\n\nCode\n# carbon_offsets_clean_issued &lt;- carbon_offsets_clean %&gt;% \n#   group_by(country) %&gt;%\n#   summarise(total_credits = sum(total_credits_issued, na.rm = TRUE)) \n# \n# \n# top_10_values &lt;- carbon_offsets_clean_issued %&gt;%\n#   top_n(10, total_credits)\n# \n# # If you want to keep only the rows with the top 10 values:\n# filtered_dataframe &lt;- carbon_offsets_clean_issued %&gt;%\n#   filter(total_credits %in% top_10_values$total_credits)\n# \n# filtered_dataframe$label = fontawesome('fa-leaf')\n# \n# ggplot(filtered_dataframe, aes(fill = country, values = total_credits)) +\n#   geom_waffle(n_rows = 20, flip = TRUE,make_proportional = TRUE, color = \"white\") +\n#   geom_text(aes(label=label), family='fontawesome-webfont')\n#   coord_equal() + \n#   paletteer::scale_fill_paletteer_d(\"rcartocolor::Earth\") +\n#   labs(title = \"Which Country has the most Carbon Credits Issued?\",\n#        subtitle = \"This shows the TOP 10 Countries who account for the most credits issued since DATE \",\n#        caption = \"caption\") +\n#   theme_void() +\n#   theme(\n#     legend.position = \"bottom\",\n#     legend.title = element_blank()\n#   )"
  },
  {
    "objectID": "posts/2024-03-14-carbon-data-viz/index.html#background-and-motivation",
    "href": "posts/2024-03-14-carbon-data-viz/index.html#background-and-motivation",
    "title": "Carbon Credits Data Visualization",
    "section": "",
    "text": "The Paris Agreement of 2015 was an international standard laid out in order to reduce \\(CO_2\\) emissions. With the Paris Aggreement, national emmisions target and regulations sprung up in order to substantially reduce global greenhouse gas emmission to hold global temperature incear to well below 2 C.\nWith these new regulations, businesses were pressured to lower their emmissions. Thuse introducing carbon markets with the promise to turn \\(CO_2\\) into a commodity.\nCarbon offsetting is a trading mechanism that allows entities such as governments, individuals, or businesses to compensate for their greenhouse gas emissions by supporting projects that reduce, avoid, or remove emissions elsewhere.\nTo Put it simply, carbon offsets involve an entity that emits greenhouse gases into the atmosphere paying for another entity to pollute less. For example, an airline in a developed country that wants to claim it is reducing its emissions can pay for a patch of rainforest to be protected in the Amazon.\nThe main research question I want to investigate is whether carbon credits are an effective way to measure carbon offset emissions. Each credit purportedly offsets a metric tonne of CO2 emissions, yet the Berkeley Carbon Trading Project reports that, ‚Äúresearch performed by [them] and others has found that many, if not most, offset credits traded on the market today do not represent real emissions reductions.‚Äù [[^1]]"
  },
  {
    "objectID": "posts/2024-03-14-carbon-data-viz/index.html#data-wrangling",
    "href": "posts/2024-03-14-carbon-data-viz/index.html#data-wrangling",
    "title": "Carbon Credits Data Visualization",
    "section": "Data Wrangling",
    "text": "Data Wrangling\n\n\nCode\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                          data cleaning & wrangling                       ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\ncarbon_offsets_clean &lt;- carbon_offsets %&gt;%\n  janitor::clean_names(case = \"snake\") %&gt;%\n  replace_with_na_all(condition = ~.x %in% c(-99999, \"#REF!\", \"N/a\", \"N/A\", \"NA\")) %&gt;%\n\n  # change char types to ints or doubles\n  mutate(total_credits_issued = as.numeric(gsub(\",\", \"\", total_credits_issued))) %&gt;%\n  mutate(total_credits_retired = as.numeric(gsub(\",\", \"\", total_credits_retired))) %&gt;%\n  mutate(total_credits_remaining = as.numeric(gsub(\",\", \"\", total_credits_remaining))) %&gt;%\n  mutate(total_buffer_pool_deposits = as.numeric(gsub(\",\", \"\", total_buffer_pool_deposits))) %&gt;%\n  mutate(first_year_of_project = as.factor(gsub(\",\", \"\", first_year_of_project))) %&gt;%\n\n  # remove irregular year columns of the structure 2001...127\n  #select_if(~!any(grepl(\"\\\\d\", .)))\n  dplyr::select(!matches(\"\\\\d\"))\n  # select(-grep(pattern = \"^[0-9]{4}\\\\.\\\\.\\\\.[0-9]{3}$\", names(.), value = TRUE)) %&gt;%\n\nyear_of_offsets &lt;- year_of_offsets %&gt;%\n  rename(year_of_offset = year)\n\ncarbon_offsets_clean_df &lt;- carbon_offsets_clean %&gt;%\n  # join with regular year data\n  full_join(year_of_offsets, by = 'project_name',relationship = \"many-to-many\")\n\n\nAfter data cleaning, I saved the cleaned dataset so that I would not have to run the cleaning script everytime. Here I simply read in the cleaned version of this carbon_offsetsdataset.\n\n\nCode\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n##                          importing data                      ----\n##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\ncarbon_offsets_clean &lt;- read_csv(here(\"data\",\"carbon_offsets_clean.csv\"))\n\n# color palettes\n\nglacier = c(\"#01353D\", \"#088096\", \"#58B3C7\", \"#7AD4E4\", \"#B8FCFC\")\neverglades = c(\"#345023\", \"#596C0B\", \"#83A102\", \"#003B68\", \"#426F86\", \"#7A712F\")\nigauzufalls = c(\"#415521\", \"#97AD3D\", \"#4C3425\", \"#7F6552\", \"#5A8093\", \"#9FBAD3\")\nolympic = c(\"#3A4330\", \"#426737\", \"#75871B\", \"#BAB97D\", \"#FDE16A\", \"#F9B40E\", \"#E88C23\", \"#A25933\")"
  },
  {
    "objectID": "posts/2024-03-14-carbon-data-viz/index.html#infographic",
    "href": "posts/2024-03-14-carbon-data-viz/index.html#infographic",
    "title": "Carbon Credits Data Visualization",
    "section": "Infographic",
    "text": "Infographic\n\nPlease look at a better Resolution Photo on my Github Repo : How are Carbon Credits Distributed Infographic"
  }
]